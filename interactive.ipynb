{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b28d9a2-caad-4a77-9eb9-25706c1e57ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import zipfile\n",
    "import json\n",
    "import torch\n",
    "from unidecode import unidecode\n",
    "import spacy\n",
    "from util.file_util import cached_path, get_root_path\n",
    "from dataloader import Dataloader\n",
    "from jointBERT import JointBERT\n",
    "from postprocess import recover_intent, recover_slot\n",
    "from spacy.symbols import ORTH, LEMMA, POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8d8b19e-ae1c-4685-97ef-262cf78f6b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTNLU():\n",
    "    def __init__(self, mode,folder_name,config_file,model_file):\n",
    "        assert mode == 'usr' or mode == 'sys' or mode == 'all'\n",
    "        self.mode = mode\n",
    "        current_folder = globals()['_dh'][0]+\"/\"+folder_name\n",
    "        config_file = os.path.join(current_folder, 'configs/{}'.format(config_file))\n",
    "        config = json.load(open(config_file))\n",
    "        # print(config['DEVICE'])\n",
    "        # DEVICE = config['DEVICE']\n",
    "        DEVICE = 'cpu' if not torch.cuda.is_available() else 'cuda:0'\n",
    "        root_dir = os.path.dirname(current_folder)\n",
    "        data_dir = os.path.join(root_dir, config['data_dir'])\n",
    "        output_dir = os.path.join(root_dir, config['output_dir'])\n",
    "\n",
    "        intent_vocab = json.load(open(os.path.join(data_dir, 'intent_vocab.json')))\n",
    "        tag_vocab = json.load(open(os.path.join(data_dir, 'tag_vocab.json')))\n",
    "        dataloader = Dataloader(intent_vocab=intent_vocab, tag_vocab=tag_vocab,\n",
    "                                pretrained_weights=config['model']['pretrained_weights'])\n",
    "\n",
    "        best_model_path = os.path.join(output_dir, 'pytorch_model.bin')\n",
    "        if not os.path.exists(best_model_path):\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "            print('Load from model_file param')\n",
    "            archive_file = cached_path(model_file)\n",
    "            archive = zipfile.ZipFile(archive_file, 'r')\n",
    "            archive.extractall(root_dir)\n",
    "            archive.close()\n",
    "        # print('Load from', best_model_path)\n",
    "        model = JointBERT(config['model'], DEVICE, dataloader.tag_dim, dataloader.intent_dim)\n",
    "        model.load_state_dict(torch.load(os.path.join(output_dir, 'pytorch_model.bin'), DEVICE))\n",
    "        model.to(DEVICE)\n",
    "        model.eval()\n",
    "\n",
    "        self.model = model\n",
    "        self.use_context = config['model']['context']\n",
    "        self.dataloader = dataloader\n",
    "        self.nlp = spacy.load('en_core_web_sm')\n",
    "        try:\n",
    "            self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        except Exception:\n",
    "            print('download en_core_web_sm for spacy')\n",
    "            from spacy.cli.download import download as spacy_download\n",
    "            spacy_download(\"en_core_web_sm\")\n",
    "            spacy_model_module = __import__(\"en_core_web_sm\")\n",
    "            self.nlp = spacy_model_module.load()\n",
    "        with open(os.path.join(globals()['_dh'][0], 'db/postcode.json'), 'r') as f:\n",
    "            token_list = json.load(f)\n",
    "\n",
    "        for token in token_list:\n",
    "            token = token.strip()\n",
    "            self.nlp.tokenizer.add_special_case(token, [{ORTH: token, LEMMA: token, POS: u'NOUN'}])\n",
    "        print(\"BERTNLU loaded\")\n",
    "\n",
    "    def predict(self, utterance, context=list()):\n",
    "        # Note: spacy cannot tokenize 'id' or 'Id' correctly.\n",
    "        utterance = re.sub(r'\\b(id|Id)\\b', 'ID', utterance)\n",
    "        # tokenization first, very important!\n",
    "        ori_word_seq = [token.text for token in self.nlp(unidecode(utterance)) if token.text.strip()]\n",
    "        # print(ori_word_seq)\n",
    "        ori_tag_seq = ['O'] * len(ori_word_seq)\n",
    "        if self.use_context:\n",
    "            if len(context) > 0 and type(context[0]) is list and len(context[0]) > 1:\n",
    "                context = [item[1] for item in context]\n",
    "            context_seq = self.dataloader.tokenizer.encode('[CLS] ' + ' [SEP] '.join(context[-3:]))\n",
    "            context_seq = context_seq[:512]\n",
    "        else:\n",
    "            context_seq = self.dataloader.tokenizer.encode('[CLS]')\n",
    "        intents = []\n",
    "        da = {}\n",
    "\n",
    "        word_seq, tag_seq, new2ori = self.dataloader.bert_tokenize(ori_word_seq, ori_tag_seq)\n",
    "        word_seq = word_seq[:510]\n",
    "        tag_seq = tag_seq[:510]\n",
    "        batch_data = [[ori_word_seq, ori_tag_seq, intents, da, context_seq,\n",
    "                       new2ori, word_seq, self.dataloader.seq_tag2id(tag_seq), self.dataloader.seq_intent2id(intents)]]\n",
    "\n",
    "        pad_batch = self.dataloader.pad_batch(batch_data)\n",
    "        pad_batch = tuple(t.to(self.model.device) for t in pad_batch)\n",
    "        word_seq_tensor, tag_seq_tensor, intent_tensor, word_mask_tensor, tag_mask_tensor, context_seq_tensor, context_mask_tensor = pad_batch\n",
    "        slot_logits, intent_logits = self.model.forward(word_seq_tensor, word_mask_tensor,\n",
    "                                                        context_seq_tensor=context_seq_tensor,\n",
    "                                                        context_mask_tensor=context_mask_tensor)\n",
    "        das = recover_intent(self.dataloader, intent_logits[0])\n",
    "        das2 = recover_slot(self.dataloader, intent_logits[0], slot_logits[0], tag_mask_tensor[0],\n",
    "                     batch_data[0][0], batch_data[0][-4])\n",
    "        dialog_act = []\n",
    "        for intent, slot, value in das2:\n",
    "            domain = intent.split('-')[0]\n",
    "            result={}\n",
    "            result[\"intent\"]=intent\n",
    "            # result[\"domain\"]=domain\n",
    "            result[\"slot\"]=slot\n",
    "            result[\"value\"]=value\n",
    "            dialog_act.append(result)\n",
    "        return dialog_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c1f6486-1c87-48e9-b015-c3b7b28a7362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-base-uncased\n",
      "BERTNLU loaded\n"
     ]
    }
   ],
   "source": [
    "text_list=[\n",
    "    \"How about rosa's bed and breakfast ? Their postcode is cb22ha.\",\n",
    "    \"I want a bus to get to Mira Mesa.\",\n",
    "    \"I would like a taxi from Gilman drive to Los angeles.\"\n",
    "]\n",
    "nlu = BERTNLU(mode='all',folder_name=\"multiwoz22\",config_file='multiwoz_all_context.json',model_file='output/all_context/bert_multiwoz_all_context.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83a73e70-698f-4b11-be0c-6aba50a83761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: How about rosa's bed and breakfast ? Their postcode is cb22ha.\n",
      "Pred  0 : {\n",
      "    \"intent\": \"Hotel-Recommend\",\n",
      "    \"slot\": \"Name\",\n",
      "    \"value\": \"rosa\"\n",
      "}\n",
      "Pred  1 : {\n",
      "    \"intent\": \"Hotel-Inform\",\n",
      "    \"slot\": \"Post\",\n",
      "    \"value\": \"cb22ha\"\n",
      "}\n",
      "Text: I want a bus to get to Mira Mesa.\n",
      "Pred  0 : {\n",
      "    \"intent\": \"Taxi-Inform\",\n",
      "    \"slot\": \"Dest\",\n",
      "    \"value\": \"Mira Mesa\"\n",
      "}\n",
      "Text: I would like a taxi from Gilman drive to Los angeles.\n",
      "Pred  0 : {\n",
      "    \"intent\": \"Taxi-Inform\",\n",
      "    \"slot\": \"Depart\",\n",
      "    \"value\": \"Gilman drive\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for text in text_list:\n",
    "    predictions=nlu.predict(text)\n",
    "    print(\"Text:\",text)\n",
    "    for i in range(len(predictions)):\n",
    "        print(\"Pred \",i,\":\",json.dumps(predictions[i],indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf4393af-b632-41db-b55c-460cc1852e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: How about rosa's bed and breakfast ? Their postcode is cb22ha.\n",
      "Context: []\n",
      "Pred  0 : {\n",
      "    \"intent\": \"Hotel-Recommend\",\n",
      "    \"slot\": \"Name\",\n",
      "    \"value\": \"rosa\"\n",
      "}\n",
      "Pred  1 : {\n",
      "    \"intent\": \"Hotel-Inform\",\n",
      "    \"slot\": \"Post\",\n",
      "    \"value\": \"cb22ha\"\n",
      "}\n",
      "Text: I want a bus to get to Mira Mesa.\n",
      "Context: [\"How about rosa's bed and breakfast ? Their postcode is cb22ha.\"]\n",
      "Pred  0 : {\n",
      "    \"intent\": \"Taxi-Inform\",\n",
      "    \"slot\": \"Dest\",\n",
      "    \"value\": \"Mira\"\n",
      "}\n",
      "Text: I would like a taxi from Gilman drive to Los angeles.\n",
      "Context: [\"How about rosa's bed and breakfast ? Their postcode is cb22ha.\", 'I want a bus to get to Mira Mesa.']\n",
      "Pred  0 : {\n",
      "    \"intent\": \"Taxi-Inform\",\n",
      "    \"slot\": \"Depart\",\n",
      "    \"value\": \"Gilman drive\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(text_list)):\n",
    "    text=text_list[j]\n",
    "    predictions=nlu.predict(text,context=text_list[:j])\n",
    "    print(\"Text:\",text)\n",
    "    print(\"Context:\",text_list[:j])\n",
    "    for i in range(len(predictions)):\n",
    "        print(\"Pred \",i,\":\",json.dumps(predictions[i],indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec50ae2d-39c2-4b54-8e61-dc02cc55a40d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
